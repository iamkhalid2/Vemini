# ğŸ¤– Vemini

A real-time multimodal communication interface built with React and TypeScript, leveraging Google's Generative AI services for context-aware AI interactions.

## âœ¨ Features

- ğŸ’¬ **Real-time Communication**: WebSocket-based audio streaming and processing
- ğŸ§ **Advanced Audio**: Web Audio API integration with volume metering and visualization
- ğŸ¤– **AI Integration**: Seamless connection with Google's Generative Language API
- ğŸ“¹ **Media Capture**: Support for webcam and screen capture
- ğŸ”„ **Real-time Processing**: Media stream multiplexing and audio worklet processing
- ğŸ›ï¸ **Modular Design**: Flexible component architecture with side panels and control trays
- ğŸ› ï¸ **Tool Integration**: Support for tool calls and responses

## ğŸ› ï¸ Technical Stack

- React + TypeScript
- Web Audio API
- WebSocket API
- Google Generative AI SDK

## ğŸ—ï¸ Project Structure

```
src/
â”œâ”€â”€ components/          # React components (Altair, AudioPulse, etc.)
â”œâ”€â”€ contexts/           # React context providers
â”œâ”€â”€ hooks/             # Custom hooks for media and API
â”œâ”€â”€ lib/               # Core utilities and audio processing
â”‚   â””â”€â”€ worklets/     # Audio worklet processors
â””â”€â”€ [other config files]
```

## ğŸš€ Setup

1. Clone the repository
2. Install dependencies:
```bash
npm install
```
3. Configure your Google API key
4. Start the development server:
```bash
npm start
```

## ğŸ“œ License

Copyright 2024 Google LLC

Licensed under the Apache License, Version 2.0
